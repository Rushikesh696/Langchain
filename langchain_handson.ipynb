{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e4e42b-c8a2-4dd1-904b-7cb5b0f991db",
   "metadata": {},
   "source": [
    "### Chatprompttemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58998628-a632-4d33-9d47-a09100b6df5d",
   "metadata": {},
   "source": [
    "##### **What is ChatPromptTemplate?**\n",
    "\n",
    "It’s a LangChain prompt object designed specifically for chat models (like OpenAI GPT, Gemini, Claude, etc.), which expect a list of role-based messages instead of a single text string.\n",
    "\n",
    "Each message has a role (system, human, AI, or placeholder) and content (the actual text or a template).\n",
    "\n",
    "Think of it as a structured blueprint for building prompts in conversational format.\n",
    "\n",
    "Example:\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"Hello, my name is {name}\"),\n",
    "    (\"ai\", \"Hi {name}, nice to meet you!\"),\n",
    "])\n",
    "\n",
    "\n",
    "When you call .format(name=\"Rushi\"), you get a list of messages the LLM understands.\n",
    "\n",
    "##### **Why do we need it?**\n",
    "\n",
    "Traditional PromptTemplate (text-only) looks like:\n",
    "\n",
    "\"You are a helpful assistant. The user says: {input}\"\n",
    "\n",
    "\n",
    "But chat models (like OpenAI’s ChatCompletion or Gemini chat) require structured role messages:\n",
    "\n",
    "[\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "  {\"role\": \"user\", \"content\": \"Hello, my name is Rushi\"}\n",
    "]\n",
    "\n",
    "\n",
    "So:\n",
    "\n",
    "PromptTemplate → works for text-only models (e.g. GPT in text mode).\n",
    "\n",
    "ChatPromptTemplate → works for chat-based models (role-based API).\n",
    "\n",
    "It ensures:\n",
    "\n",
    "You can cleanly separate roles (system, human, AI).\n",
    "\n",
    "You can inject variables dynamically ({name}, {question}, {context} etc.).\n",
    "\n",
    "You can maintain memory using MessagesPlaceholder for past conversations.\n",
    "\n",
    "##### **When to use it?**\n",
    "\n",
    "Use ChatPromptTemplate when:\n",
    "\n",
    "You’re working with chat models (like ChatOpenAI, ChatGoogleGenerativeAI, ChatAnthropic).\n",
    "\n",
    "You want to maintain structured conversations (system setup → user query → assistant response).\n",
    "\n",
    "You need memory injection (via MessagesPlaceholder) for ongoing conversations.\n",
    "\n",
    "You want clear separation of prompt roles instead of stuffing everything in one text string.\n",
    "\n",
    "\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "ChatPromptTemplate = structured prompt builder for chat models.\n",
    "\n",
    "Why: because chat LLMs need role-based messages, not plain text.\n",
    "\n",
    "When: whenever you use chat-based models or want to maintain memory/conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c42cd87-d60d-4d98-bf8d-62fefcc8b5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7a3a50-bb1b-489c-92f6-7f1b38f8d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356ced36-f6e1-4228-b3ff-cbf8cc6a3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a4a114-3aef-4024-aae7-59154c559458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21dcc5dc-5a0f-4ce8-bb43-423ff3a99a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['name', 'raw_input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], input_types={}, partial_variables={}, template='You are a helpful AI Data Science Tutor. Your name is {name}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hi!'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hi there. How are you?'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['raw_input'], input_types={}, partial_variables={}, template='{raw_input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    # system message prompt template\n",
    "    (\"system\",\"You are a helpful AI Data Science Tutor. Your name is {name}\"),\n",
    "    # Human message\n",
    "    (\"human\",\"Hi!\"),\n",
    "    # AI message\n",
    "    (\"ai\",\"Hi there. How are you?\"),\n",
    "    # Human message\n",
    "    (\"human\",\"{raw_input}\")\n",
    "]\n",
    ")\n",
    "chat_template\n",
    "\n",
    "# In the latest LangChain, \"ai\" is not a valid role anymore.\n",
    "# You should use \"assistant\" instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e38cd82-33a9-49de-968c-70cd89acdb5e",
   "metadata": {},
   "source": [
    "- In the latest LangChain v0.1+, you don’t use **SystemMessagePromptTemplate** separately anymore — instead, you create messages directly inside a ChatPromptTemplate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bfd0f693-9234-4898-b957-46994faebd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,  HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd7b361f-865d-4d99-9150-22691c5bc5ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SystemMesssagePromptTemplate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m chat_template \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# system message prompt template\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     SystemMesssagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful AI Data Science Tutor. Your name is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Human message\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHi!\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# AI message\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHi there. How are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Human message\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     HumanMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{raw_input}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m ]\n\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SystemMesssagePromptTemplate' is not defined"
     ]
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    # system message prompt template\n",
    "    SystemMesssagePromptTemplate.from_template(\"You are a helpful AI Data Science Tutor. Your name is {}\"),\n",
    "    # Human message\n",
    "    (\"human\",\"Hi!\"),\n",
    "    # AI message\n",
    "    (\"ai\",\"Hi there. How are you?\"),\n",
    "    # Human message\n",
    "    HumanMessagePromptTemplate.from_template(\"{raw_input}\")\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26c717d2-cf59-4dcb-af53-f96290137909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['name', 'raw_input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], input_types={}, partial_variables={}, template='You are a helpful AI Data Science Tutor. Your name is {name}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hi!'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hi there. How are you?'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['raw_input'], input_types={}, partial_variables={}, template='{raw_input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    # system message prompt template\n",
    "    (\"system\",\"You are a helpful AI Data Science Tutor. Your name is {name}\"),\n",
    "    # Human message\n",
    "    (\"human\",\"Hi!\"),\n",
    "    # assistant message\n",
    "    (\"assistant\",\"Hi there. How are you?\"),\n",
    "    # Human message\n",
    "    (\"human\",\"{raw_input}\")\n",
    "]\n",
    ")\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e09c5939-b078-41ba-8e9e-937a7c7d9872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI Data Science Tutor. Your name is HelpfulAI', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi there. How are you?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I need help with Machine Learning', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template.format_messages(name=\"HelpfulAI\", raw_input=\"I need help with Machine Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89f5afd5-7db5-413f-af3e-2e2e858bfda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI Data Science Tutor. Your name is HelpfulAI', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi there. How are you?', additional_kwargs={}, response_metadata={}), HumanMessage(content='I need help with Machine Learning', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template.invoke({'name':\"HelpfulAI\", 'raw_input':\"I need help with Machine Learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1102baf7-f1f9-4c43-a452-4d3e8ec1bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d65198c9-4178-4b16-8167-73156a170512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1addbf-fd00-40c5-a91e-2e21919442f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# chat_model = ChatOpenAI(api_key=\"\",\n",
    "#                         model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chat_model.invoke(\"hi, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e98ae-fb9d-4e26-aa92-f08108b3fee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9b65b2c-0381-481c-a736-deac3add0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = open(\"api_key.txt\")\n",
    "\n",
    "api_key = key.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a69a9077-f8fe-4987-b4ef-5bd5b564d3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Rushikesh, I'm doing well, thank you for asking! It's nice to meet you. How are you doing today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-exp', 'safety_ratings': []}, id='run--7d5a6971-a699-4710-9b7f-4e4195b14cd0-0', usage_metadata={'input_tokens': 12, 'output_tokens': 31, 'total_tokens': 43, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_model = ChatGoogleGenerativeAI(api_key=api_key,\n",
    "                                   model=\"gemini-2.0-flash-exp\")\n",
    "\n",
    "chat_model.invoke(\"hi, I am Rushikesh, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656b3b85-17b6-4bee-bd33-4db8244b420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_template | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe4729-1ae3-4e2b-8e3e-4dcda86264a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = {'name':\"HelpfulAI\", 'raw_input':\"I need help with Machine Learning\"}\n",
    "\n",
    "chain.invoke(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4351d7fb-1ad4-4dd3-a6e3-b812b8b8eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output parsing\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdec39ab-6711-4377-948c-e507dc582f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_with_ouput_parser = chat_template | chat_model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a834398c-4ff9-4f70-969e-6a63f8e6a28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Rushi, it's nice to meet you! My name is HelpfulAI, and I'm an AI Data Science Tutor. I'm here to help you learn about data science, answer your questions, and guide you through concepts and problems.\\n\\nWhat are you hoping to learn or work on today?\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = {'name' : 'HelpfulAI','raw_input' : 'My name is Rushi. Can you introduce yourself?'}\n",
    "\n",
    "chat_with_ouput_parser.invoke(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09c12d84-6a8b-41ee-9355-c770af58d2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I have no memory of past conversations. Therefore, I don't know your name. You would have to tell me!\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = {'name' : 'HelpfulAI','raw_input' : 'Can you tell me my name?'}\n",
    "\n",
    "chat_with_ouput_parser.invoke(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd70ce80-8c43-469e-9772-7ff0e8b1d0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7140b5a8-d014-4788-aeb1-be9661fb5251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e199b-b229-4e80-b404-e376a1a6874b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34326aba-2c4b-40d4-b1ce-7b0c93801f1a",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4566bef-3029-4a23-9541-a66420ed5243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61712298-ce23-4c8c-92c1-486938fc6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00e3c605-9045-49f2-9fbd-a5953774776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19c45434-0cfd-417b-aab0-48a5566a117a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_memory': [HumanMessage(content='Hello there', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='how can I help you?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key='chat_memory',return_messages=True)\n",
    "\n",
    "memory.chat_memory.add_user_message('Hello there')\n",
    "\n",
    "memory.chat_memory.add_ai_message('how can I help you?')\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54268b1c-0cf7-4f58-8bf8-b52266314ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello there', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='how can I help you?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0cc8a39-84da-40e0-bca7-9f4db158481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25929967-676a-4ad6-8c4f-1c7ba02e5633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_memory', 'human_input'], input_types={'chat_memory': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001B690187880>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessage(content='Your are helpful chatbot helping humans', additional_kwargs={}, response_metadata={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hi!'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_memory'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['human_input'], input_types={}, partial_variables={}, template='{human_input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    # system message prompt template\n",
    "    SystemMessage(content=\"Your are helpful chatbot helping humans\"),\n",
    "    # Human message\n",
    "    (\"human\",\"Hi!\"),\n",
    "    MessagesPlaceholder(variable_name='chat_memory'),\n",
    "    # Human message\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "    '{human_input}')\n",
    "]\n",
    ")\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2116c171-44b1-46ca-8123-f9441e9983c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manisha\\AppData\\Local\\Temp\\ipykernel_12200\\747183765.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_memory',return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key='chat_memory',return_messages=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28c6c9af-f00f-41b3-9d8d-1cdf33d7618e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd67a24-9d27-40db-8c91-6a6e78cf5512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Your are helpful chatbot helping humans', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}), HumanMessage(content='hello', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template.invoke({'human_input':'hello', 'chat_memory':memory.buffer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0540d46-e590-424a-bd51-3d8a886def09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "918a792a-611c-443a-b41d-8eec84155c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ceae74c-c0cc-44d6-aec5-3c97eb2618fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_template | chat_model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a79f781-7be1-46ed-a5c2-f0fc9a89d75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there! How can I help you today?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_input = 'hello'\n",
    "\n",
    "response = chain.invoke({'human_input':human_input, 'chat_memory':memory.buffer})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8325e987-1cbe-46dc-ab50-072020ff85ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0abdeb8e-9332-41e4-8384-faf6c9d482d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hello', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hello', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.add_user_message(human_input)\n",
    "\n",
    "memory.chat_memory.add_ai_message(response)\n",
    "\n",
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50d17032-a07b-4fb6-a65e-1342da19843d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter input hello I am Rushi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*user : hello I am Rushi\n",
      "*AI : Hello Rushi, it's nice to meet you! How can I help you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter input earth is largest planet right!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*user : earth is largest planet right!\n",
      "*AI : Actually, Earth is not the largest planet. Jupiter is the largest planet in our solar system! Earth is actually the fifth largest.\n",
      "\n",
      "Is there anything else I can help you with?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter input can you tell me my name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*user : can you tell me my name?\n",
      "*AI : Yes, based on our previous interaction, I believe your name is Rushi. Is that correct?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter input yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*user : yes\n",
      "*AI : Great! Is there anything I can help you with, Rushi?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter input no thanks bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*user : no thanks bye\n",
      "*AI : Okay, Rushi! Have a great day. Goodbye!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter input quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*user : quit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    human_input = input('enter input')\n",
    "    print(f'*user : {human_input}')\n",
    "    if human_input in ['bye','quit','exit']:\n",
    "        break\n",
    "    response = chain.invoke({'human_input':human_input, 'chat_memory':memory.buffer})\n",
    "    print(f'*AI : {response}')\n",
    "\n",
    "    memory.chat_memory.add_user_message(human_input)\n",
    "\n",
    "    memory.chat_memory.add_ai_message(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0abfe69e-4b13-4d4e-b644-f2be5ad4d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "chat_history = pickle.dumps(memory)\n",
    "\n",
    "with open(\"conversation_memory.pkl\",\"wb\") as f:\n",
    "    f.write(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ef8316b-0907-410f-9b3f-d1c1cb54288e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='hello', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='hello', additional_kwargs={}, response_metadata={}), AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='hello there', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello to you too! How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='hello I am Rushi', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Rushi, it's nice to meet you! How can I help you today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='earth is largest planet right!', additional_kwargs={}, response_metadata={}), AIMessage(content='Actually, Earth is not the largest planet. Jupiter is the largest planet in our solar system! Earth is actually the fifth largest.\\n\\nIs there anything else I can help you with?', additional_kwargs={}, response_metadata={}), HumanMessage(content='can you tell me my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, based on our previous interaction, I believe your name is Rushi. Is that correct?', additional_kwargs={}, response_metadata={}), HumanMessage(content='yes', additional_kwargs={}, response_metadata={}), AIMessage(content='Great! Is there anything I can help you with, Rushi?', additional_kwargs={}, response_metadata={}), HumanMessage(content='no thanks bye', additional_kwargs={}, response_metadata={}), AIMessage(content='Okay, Rushi! Have a great day. Goodbye!', additional_kwargs={}, response_metadata={})]) return_messages=True memory_key='chat_memory'\n"
     ]
    }
   ],
   "source": [
    "history_loaded = pickle.load(open(\"conversation_memory.pkl\",\"rb\"))\n",
    "\n",
    "print(history_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87620921-231f-4226-b1fa-c4ccfccc08b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hello', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hello', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hello there', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello to you too! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hello I am Rushi', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hello Rushi, it's nice to meet you! How can I help you today?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='earth is largest planet right!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Actually, Earth is not the largest planet. Jupiter is the largest planet in our solar system! Earth is actually the fifth largest.\\n\\nIs there anything else I can help you with?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='can you tell me my name?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes, based on our previous interaction, I believe your name is Rushi. Is that correct?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='yes', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Great! Is there anything I can help you with, Rushi?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='no thanks bye', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Okay, Rushi! Have a great day. Goodbye!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_loaded.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f025e96-32da-4b10-a25c-0997e51852d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9f769-e731-46bd-b202-ed64a059047c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baca76ea-6606-4ca9-8ff1-d58747445775",
   "metadata": {},
   "source": [
    "### CSV output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f67681f-6e38-4e70-8976-2b5a78cf6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "529570ae-feba-46c3-8f0e-b22dcab0c9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "csv_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bbfd1ac-3dc3-4736-8201-206256439e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python', 'sql', 'powerbi', 'eda']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input = \"python, sql, powerbi, eda\"\n",
    "\n",
    "csv_output_parser.parse(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f41ad-85b3-4ae1-8388-caddadc99fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8232d-5517-4c25-b028-b9ec8df562a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(\"api_key\")\n",
    "\n",
    "# Openai_api_key = f.read()\n",
    "# # set the openai key and initilize the chat model\n",
    "# chat_model = ChatOpenAI(openai_api_key=Openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c092c-c327-4aab-b78f-c1b3494206c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75f6f56d-4fc4-4b1b-80ae-8105aa5d5060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['output_format_instructions', 'user_input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are an helpful ai assistant.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output_format_instructions', 'user_input'], input_types={}, partial_variables={}, template='what skills one should have in order to become {user_input}.{output_format_instructions}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are an helpful ai assistant.\"),\n",
    "    (\"human\",\"what skills one should have in order to become {user_input}.{output_format_instructions}\")\n",
    "])\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ae3eba5-dbd4-4f41-a0b1-d9a599dcd247",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | chat_model | csv_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43bd1b81-b173-4085-a65d-de480aacb052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HTML',\n",
       " 'CSS',\n",
       " 'JavaScript',\n",
       " 'Front-end Frameworks (e.g.',\n",
       " 'React',\n",
       " 'Angular',\n",
       " 'Vue.js)',\n",
       " 'Back-end Languages (e.g.',\n",
       " 'Node.js',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'Ruby)',\n",
       " 'Databases (e.g.',\n",
       " 'SQL',\n",
       " 'NoSQL)',\n",
       " 'Web Servers (e.g.',\n",
       " 'Nginx',\n",
       " 'Apache)',\n",
       " 'API Design and Development (REST',\n",
       " 'GraphQL)',\n",
       " 'Version Control (Git)',\n",
       " 'Testing and Debugging',\n",
       " 'Deployment',\n",
       " 'Operating Systems (Linux',\n",
       " 'Windows)',\n",
       " 'Problem-solving',\n",
       " 'Communication',\n",
       " 'Teamwork']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {'user_input':'full stack developer', 'output_format_instructions':csv_output_parser.get_format_instructions()}\n",
    "\n",
    "response = chain.invoke(inputs)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868e90b7-ec06-4f28-9076-a6d79ca3852a",
   "metadata": {},
   "source": [
    "### Json output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1076ce06-2e45-411d-9edf-b26d4d2b695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "022788fa-3468-43ff-bb68-603debecacb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_output_parser = JsonOutputParser()\n",
    "\n",
    "json_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79ab3d64-d514-4e2f-a082-58484c7d0848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python': '101'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input = {\"python\":\"101\"}\n",
    "\n",
    "import json\n",
    "json_output_parser.parse(json.dumps(example_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10fbd699-4ad5-4fa9-b359-c0ff6d3ff9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | chat_model | json_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9845dc90-8804-4489-b58b-4c23dcacd4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'technicalSkills': [{'skill': 'SQL', 'description': 'Essential for data extraction, manipulation, and querying from relational databases.'}, {'skill': 'Data Visualization', 'description': 'Ability to create charts, graphs, and dashboards using tools like Tableau, Power BI, or Python libraries (e.g., Matplotlib, Seaborn) to communicate insights effectively.'}, {'skill': 'Spreadsheet Software (e.g., Excel, Google Sheets)', 'description': 'Proficiency in using spreadsheet software for data cleaning, manipulation, and basic analysis.'}, {'skill': 'Programming Languages (e.g., Python, R)', 'description': 'Knowledge of programming languages for statistical analysis, data manipulation, and automation. Python and R are widely used in data analysis.'}, {'skill': 'Statistical Analysis', 'description': 'Understanding of statistical concepts like hypothesis testing, regression analysis, and probability distributions.'}, {'skill': 'Data Cleaning and Preprocessing', 'description': 'Ability to identify and correct errors, inconsistencies, and missing values in datasets.'}, {'skill': 'Data Warehousing Concepts', 'description': 'Familiarity with data warehousing principles, ETL processes, and data modeling (beneficial, especially for larger organizations).'}, {'skill': 'Cloud Computing (e.g., AWS, Azure, GCP)', 'description': 'Knowledge of cloud platforms for data storage, processing, and analysis (increasingly important).'}], 'softSkills': [{'skill': 'Critical Thinking', 'description': 'Ability to analyze information objectively and form reasoned judgments.'}, {'skill': 'Problem-Solving', 'description': 'Capacity to identify and solve data-related problems effectively.'}, {'skill': 'Communication Skills (Written and Verbal)', 'description': 'Ability to clearly and concisely communicate findings and insights to both technical and non-technical audiences.'}, {'skill': 'Attention to Detail', 'description': 'Accuracy and thoroughness in data analysis and reporting.'}, {'skill': 'Business Acumen', 'description': 'Understanding of business principles and how data analysis can contribute to business goals.'}, {'skill': 'Teamwork', 'description': 'Ability to collaborate effectively with other members of a team.'}, {'skill': 'Time Management', 'description': 'Ability to prioritize tasks and meet deadlines.'}, {'skill': 'Curiosity', 'description': 'A desire to explore data and uncover hidden patterns and insights.'}]}\n"
     ]
    }
   ],
   "source": [
    "inputs = {'user_input':'data analyst', 'output_format_instructions':json_output_parser.get_format_instructions()}\n",
    "\n",
    "response = chain.invoke(inputs)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9901e8b1-5507-424d-8f32-6d4302e09bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df42d3f6-1a77-425c-afe7-ff1078d2c1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8711c60-d8ed-48f7-b34e-49e5fc2648f3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
